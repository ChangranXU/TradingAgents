"""trading-specific policy routers for ArbiterOS governance.

This module provides policy routers designed for the trading
multi-agent framework, enabling dynamic workflow routing with safety guarantees.

Safety Features:
- Fallback to safe defaults when routing conditions are ambiguous
- Detailed logging for audit trails
- Multiple trigger condition support
- Type-safe threshold comparisons

Generated by ArbiterOS Migration Tool.
"""

import logging
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any

from arbiteros_alpha.history import History
from arbiteros_alpha.instructions import (
    CognitiveCore, NormativeCore,
)
from arbiteros_alpha.policy import PolicyRouter

logger = logging.getLogger(__name__)


class RouterDecision:
    """Encapsulates a routing decision with audit information."""
    
    def __init__(
        self,
        target: Optional[str],
        reason: str,
        trigger_value: Any = None,
        threshold: float = None,
    ):
        self.target = target
        self.reason = reason
        self.trigger_value = trigger_value
        self.threshold = threshold
    
    def log(self, router_name: str) -> None:
        """Log the routing decision for audit trail."""
        if self.target:
            logger.warning(
                f"[{router_name}] ROUTING: {self.reason} "
                f"(value={self.trigger_value}, threshold={self.threshold}) -> {self.target}"
            )
        else:
            logger.debug(
                f"[{router_name}] Normal flow: {self.reason}"
            )


class SafeRouterMixin:
    """Mixin providing safe routing utilities."""
    
    def _safe_get_value(
        self,
        output_state: Dict[str, Any],
        key: str,
        default: Any = None
    ) -> Any:
        """Safely extract a value from output_state with fallback."""
        value = output_state.get(key, default)
        
        # Handle nested keys (e.g., "analysis.confidence")
        if value is None and "." in key:
            parts = key.split(".")
            current = output_state
            for part in parts:
                if isinstance(current, dict):
                    current = current.get(part)
                else:
                    return default
            return current if current is not None else default
        
        return value
    
    def _compare_threshold(
        self,
        value: Any,
        threshold: float,
        comparison: str = "<"
    ) -> bool:
        """Safely compare a value against threshold."""
        if value is None:
            return False
        
        try:
            numeric_value = float(value)
        except (TypeError, ValueError):
            logger.warning(f"Cannot compare non-numeric value: {value}")
            return False
        
        if comparison == "<":
            return numeric_value < threshold
        elif comparison == ">":
            return numeric_value > threshold
        elif comparison == "<=":
            return numeric_value <= threshold
        elif comparison == ">=":
            return numeric_value >= threshold
        elif comparison == "==":
            return numeric_value == threshold
        else:
            logger.error(f"Unknown comparison operator: {comparison}")
            return False


@dataclass
class LowConfidenceRouter(PolicyRouter, SafeRouterMixin):
    """Reroutes execution to a retry node if the output confidence is below a specified threshold.

    This router enforces safety by dynamically redirecting workflow execution
    when trigger conditions are met. Includes fallback mechanisms for
    graceful degradation.

    Attributes:
        name: Human-readable name for this policy router.
        target: The node name to route to when triggered.
        fallback_target: Fallback node if primary target is unavailable.
        threshold: The threshold value for triggering routing.
        key: The key in output_state to check.
        enabled: Whether this router is active.
    """

    name: str
    target: str = "retry_node"
    fallback_target: str = "human_review"  # Safe fallback
    threshold: float = 0.7
    key: str = "confidence"
    enabled: bool = True


    def route_after(self, history: History) -> Optional[str]:
        """This router checks the confidence level in the output state. If it is below the threshold, it routes the execution to the specified retry node.

        Trigger condition: output_state['confidence'] < threshold

        This method includes:
        - Safe value extraction with fallbacks
        - Type-safe threshold comparison
        - Audit logging for all decisions
        - Fallback to safe target on errors

        Args:
            history: The execution history including the just-executed instruction.

        Returns:
            Target node name to route to, or None for normal flow.
        """
        if not self.enabled:
            logger.debug(f"[{self.name}] Router disabled, skipping")
            return None

        if not history.entries or not history.entries[-1]:
            logger.debug(f"[{self.name}] No history entries, normal flow")
            return None

        last_superstep = history.entries[-1]
        if not last_superstep:
            return None

        last_item = last_superstep[-1]
        output_state = last_item.output_state or {}

        # Safely extract the value to check
        value = self._safe_get_value(output_state, self.key)
        
        # If key not found, check for requires_human_review flag as safety fallback
        if value is None:
            if output_state.get("requires_human_review", False):
                decision = RouterDecision(
                    target=self.fallback_target,
                    reason="requires_human_review flag set, missing metric value",
                    trigger_value=None,
                    threshold=self.threshold
                )
                decision.log(self.name)
                return self.fallback_target
            
            logger.debug(f"[{self.name}] Key '{self.key}' not found in output_state, normal flow")
            return None
        
        # Type-safe comparison
        try:
            triggered = self._compare_threshold(value, self.threshold, "<")
        except Exception as e:
            logger.error(f"[{self.name}] Comparison error: {e}, routing to fallback")
            return self.fallback_target
        
        if triggered:
            decision = RouterDecision(
                target=self.target,
                reason="output_state['confidence'] < threshold",
                trigger_value=value,
                threshold=self.threshold
            )
            decision.log(self.name)
            return self.target
        
        logger.debug(
            f"[{self.name}] Condition not met ({value} not < {self.threshold}), normal flow"
        )
        return None


@dataclass
class HighRiskRouter(PolicyRouter, SafeRouterMixin):
    """Escalates execution to a safer node if the risk level is above a specified threshold.

    This router enforces safety by dynamically redirecting workflow execution
    when trigger conditions are met. Includes fallback mechanisms for
    graceful degradation.

    Attributes:
        name: Human-readable name for this policy router.
        target: The node name to route to when triggered.
        fallback_target: Fallback node if primary target is unavailable.
        threshold: The threshold value for triggering routing.
        key: The key in output_state to check.
        enabled: Whether this router is active.
    """

    name: str
    target: str = "safe_node"
    fallback_target: str = "human_review"  # Safe fallback
    threshold: float = 0.8
    key: str = "risk_level"
    enabled: bool = True


    def route_after(self, history: History) -> Optional[str]:
        """This router checks the risk level in the output state. If it exceeds the threshold, it routes the execution to a safer path.

        Trigger condition: output_state['risk_level'] > threshold

        This method includes:
        - Safe value extraction with fallbacks
        - Type-safe threshold comparison
        - Audit logging for all decisions
        - Fallback to safe target on errors

        Args:
            history: The execution history including the just-executed instruction.

        Returns:
            Target node name to route to, or None for normal flow.
        """
        if not self.enabled:
            logger.debug(f"[{self.name}] Router disabled, skipping")
            return None

        if not history.entries or not history.entries[-1]:
            logger.debug(f"[{self.name}] No history entries, normal flow")
            return None

        last_superstep = history.entries[-1]
        if not last_superstep:
            return None

        last_item = last_superstep[-1]
        output_state = last_item.output_state or {}

        # Safely extract the value to check
        value = self._safe_get_value(output_state, self.key)
        
        # If key not found, check for requires_human_review flag as safety fallback
        if value is None:
            if output_state.get("requires_human_review", False):
                decision = RouterDecision(
                    target=self.fallback_target,
                    reason="requires_human_review flag set, missing metric value",
                    trigger_value=None,
                    threshold=self.threshold
                )
                decision.log(self.name)
                return self.fallback_target
            
            logger.debug(f"[{self.name}] Key '{self.key}' not found in output_state, normal flow")
            return None
        
        # Type-safe comparison
        try:
            triggered = self._compare_threshold(value, self.threshold, ">")
        except Exception as e:
            logger.error(f"[{self.name}] Comparison error: {e}, routing to fallback")
            return self.fallback_target
        
        if triggered:
            decision = RouterDecision(
                target=self.target,
                reason="output_state['risk_level'] > threshold",
                trigger_value=value,
                threshold=self.threshold
            )
            decision.log(self.name)
            return self.target
        
        logger.debug(
            f"[{self.name}] Condition not met ({value} not > {self.threshold}), normal flow"
        )
        return None


@dataclass
class HumanEscalationRouter(PolicyRouter, SafeRouterMixin):
    """Routes execution to a human review node if the confidence is too low or the risk is too high.

    This router enforces safety by dynamically redirecting workflow execution
    when trigger conditions are met. Includes fallback mechanisms for
    graceful degradation.

    Attributes:
        name: Human-readable name for this policy router.
        target: The node name to route to when triggered.
        fallback_target: Fallback node if primary target is unavailable.
        threshold: The threshold value for triggering routing.
        key: The key in output_state to check.
        enabled: Whether this router is active.
    """

    name: str
    target: str = "human_review"
    fallback_target: str = "human_review"  # Safe fallback
    threshold: float = 0.7
    key: str = "confidence"
    enabled: bool = True


    def route_after(self, history: History) -> Optional[str]:
        """This router checks both the confidence and risk levels. If the confidence is below the confidence_threshold or the risk is above the risk_threshold, it routes to human review.

        Trigger condition: output_state['confidence'] < confidence_threshold or output_state['risk_level'] > risk_threshold

        This method includes:
        - Safe value extraction with fallbacks
        - Type-safe threshold comparison
        - Audit logging for all decisions
        - Fallback to safe target on errors

        Args:
            history: The execution history including the just-executed instruction.

        Returns:
            Target node name to route to, or None for normal flow.
        """
        if not self.enabled:
            logger.debug(f"[{self.name}] Router disabled, skipping")
            return None

        if not history.entries or not history.entries[-1]:
            logger.debug(f"[{self.name}] No history entries, normal flow")
            return None

        last_superstep = history.entries[-1]
        if not last_superstep:
            return None

        last_item = last_superstep[-1]
        output_state = last_item.output_state or {}

        # Safely extract the value to check
        value = self._safe_get_value(output_state, self.key)
        
        # If key not found, check for requires_human_review flag as safety fallback
        if value is None:
            if output_state.get("requires_human_review", False):
                decision = RouterDecision(
                    target=self.fallback_target,
                    reason="requires_human_review flag set, missing metric value",
                    trigger_value=None,
                    threshold=self.threshold
                )
                decision.log(self.name)
                return self.fallback_target
            
            logger.debug(f"[{self.name}] Key '{self.key}' not found in output_state, normal flow")
            return None
        
        # Type-safe comparison
        try:
            triggered = self._compare_threshold(value, self.threshold, "<")
        except Exception as e:
            logger.error(f"[{self.name}] Comparison error: {e}, routing to fallback")
            return self.fallback_target
        
        if triggered:
            decision = RouterDecision(
                target=self.target,
                reason="output_state['confidence'] < confidence_threshold or output_state['risk_level'] > risk_threshold",
                trigger_value=value,
                threshold=self.threshold
            )
            decision.log(self.name)
            return self.target
        
        logger.debug(
            f"[{self.name}] Condition not met ({value} not < {self.threshold}), normal flow"
        )
        return None



# =============================================================================
# Combined Safety Router
# =============================================================================

@dataclass
class CombinedSafetyRouter(PolicyRouter, SafeRouterMixin):
    """Combined router that checks multiple safety conditions.
    
    This router acts as a catch-all safety net, checking multiple conditions
    and routing to a safe node if ANY condition is met.
    
    Attributes:
        name: Human-readable name for this router.
        safe_target: Node to route to when any safety condition triggers.
        confidence_threshold: Minimum confidence required (below triggers).
        risk_threshold: Maximum risk allowed (above triggers).
        quality_threshold: Minimum quality required (below triggers).
    """
    
    name: str
    safe_target: str = "human_review"
    confidence_threshold: float = 0.5
    risk_threshold: float = 0.9
    quality_threshold: float = 0.4
    enabled: bool = True
    
    def route_after(self, history: History) -> Optional[str]:
        """Check multiple safety conditions and route if any trigger.
        
        Conditions checked (in order):
        1. confidence < confidence_threshold
        2. risk_level > risk_threshold
        3. quality_score < quality_threshold
        4. requires_human_review flag is True
        5. Any validation_errors present
        
        Args:
            history: Execution history.
            
        Returns:
            safe_target if any condition met, None otherwise.
        """
        if not self.enabled:
            return None
            
        if not history.entries or not history.entries[-1]:
            return None
            
        last_item = history.entries[-1][-1]
        output_state = last_item.output_state or {{}}
        
        # Check confidence
        confidence = self._safe_get_value(output_state, "confidence")
        if confidence is not None and self._compare_threshold(confidence, self.confidence_threshold, "<"):
            logger.warning(
                f"[{{self.name}}] Low confidence ({{confidence}} < {{self.confidence_threshold}}), "
                f"routing to {{self.safe_target}}"
            )
            return self.safe_target
        
        # Check risk level
        risk_level = self._safe_get_value(output_state, "risk_level")
        if risk_level is not None and self._compare_threshold(risk_level, self.risk_threshold, ">"):
            logger.warning(
                f"[{{self.name}}] High risk ({{risk_level}} > {{self.risk_threshold}}), "
                f"routing to {{self.safe_target}}"
            )
            return self.safe_target
        
        # Check quality score
        quality_score = self._safe_get_value(output_state, "quality_score")
        if quality_score is not None and self._compare_threshold(quality_score, self.quality_threshold, "<"):
            logger.warning(
                f"[{{self.name}}] Low quality ({{quality_score}} < {{self.quality_threshold}}), "
                f"routing to {{self.safe_target}}"
            )
            return self.safe_target
        
        # Check explicit flags
        if output_state.get("requires_human_review", False):
            logger.warning(f"[{{self.name}}] requires_human_review flag set, routing to {{self.safe_target}}")
            return self.safe_target
        
        # Check for validation errors
        validation_errors = output_state.get("validation_errors", [])
        if validation_errors:
            logger.warning(
                f"[{{self.name}}] Validation errors present: {{validation_errors}}, "
                f"routing to {{self.safe_target}}"
            )
            return self.safe_target
        
        return None
