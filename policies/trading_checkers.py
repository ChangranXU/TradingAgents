"""trading-specific policy checkers for ArbiterOS governance.

This module provides policy checkers designed for the trading
multi-agent framework, enforcing workflow constraints and safety requirements.

PolicyCheckers validate execution constraints BEFORE instruction execution.
If validation fails, the checker returns False and blocks the execution,
preventing unsafe or invalid operations from proceeding.

Generated by ArbiterOS Migration Tool.
"""

import logging
from dataclasses import dataclass, field
from typing import List, Set, Optional

from arbiteros_alpha.history import History
from arbiteros_alpha.instructions import (
    CognitiveCore,
    ExecutionCore,
    MetacognitiveCore,
    NormativeCore,
)
from arbiteros_alpha.policy import PolicyChecker

logger = logging.getLogger(__name__)


class PolicyViolationError(Exception):
    """Raised when a policy check fails and blocks execution."""
    
    def __init__(self, policy_name: str, message: str, history_context: dict = None):
        self.policy_name = policy_name
        self.message = message
        self.history_context = history_context or {}
        super().__init__(f"[{policy_name}] {message}")


@dataclass
class VerificationRequirementChecker(PolicyChecker):
    """Ensures that a VERIFY instruction has been executed before any high-risk actions are performed, such as TOOL_CALL for trades.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = VerificationRequirementChecker(
        ...     name="verificationrequirementchecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker counts the number of VERIFY instructions in the history before a high-risk action. If the count is less than min_verifications, it blocks the execution.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        verify_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == NormativeCore.VERIFY:
                    verify_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Completion/Requirement Check: Ensure minimum required executions
        total_count = sum([verify_count])
        min_required = getattr(self, 'min_required', 1)
        
        if total_count < min_required:
            # Remove f-string variables from error message template as they may not exist in context
            base_error_msg = """Execution blocked: Verification requirement not met. Required: {min_verifications}, Found: {actual_verifications}.""".split('{')[0].rstrip('.')
            error_msg = (
                f"{base_error_msg}."
                f" Required: {min_required}, Found: {total_count}"
            )
            logger.warning(f"[{self.name}] {error_msg}")
            
            if self.strict_mode:
                raise PolicyViolationError(
                    self.name, 
                    error_msg,
                    {"required": min_required, "found": total_count}
                )
            return False

        # Log successful validation
        logger.info(
            f"[{self.name}] VerificationRequirementChecker validation PASSED: "
            f"VERIFY={verify_count}"
        )

        return True


@dataclass
class DataAvailabilityChecker(PolicyChecker):
    """Ensures that all required data fields are present before processing any instructions.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = DataAvailabilityChecker(
        ...     name="dataavailabilitychecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker verifies that all specified required fields are present and not None in the input state before proceeding with the instruction.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        generate_count = 0
        reflect_count = 0
        tool_call_count = 0
        constrain_count = 0
        delegate_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == CognitiveCore.GENERATE:
                    generate_count += 1
                    last_output_state = item.output_state
                if item.instruction == CognitiveCore.REFLECT:
                    reflect_count += 1
                    last_output_state = item.output_state
                if item.instruction == ExecutionCore.TOOL_CALL:
                    tool_call_count += 1
                    last_output_state = item.output_state
                if item.instruction == NormativeCore.CONSTRAIN:
                    constrain_count += 1
                    last_output_state = item.output_state
                if item.instruction == ExecutionCore.DELEGATE:
                    delegate_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Data Availability Check: Ensure required data is present
        if last_output_state:
            required_fields = getattr(self, 'required_fields', [])
            missing_fields = [f for f in required_fields if f not in last_output_state or last_output_state[f] is None]
            
            if missing_fields:
                error_msg = (
                    f"Execution blocked: Missing required data fields: {missing_fields}."
                    f" Missing required data fields: {missing_fields}"
                )
                logger.warning(f"[{self.name}] {error_msg}")
                
                if self.strict_mode:
                    raise PolicyViolationError(
                        self.name,
                        error_msg,
                        {"missing_fields": missing_fields}
                    )
                return False

        # Log successful validation
        logger.info(
            f"[{self.name}] DataAvailabilityChecker validation PASSED: "
            f"GENERATE={generate_count}, "
            f"REFLECT={reflect_count}, "
            f"TOOL_CALL={tool_call_count}, "
            f"CONSTRAIN={constrain_count}, "
            f"DELEGATE={delegate_count}"
        )

        return True


@dataclass
class DomainCompletionChecker(PolicyChecker):
    """Ensures that all necessary workflow stages are completed before proceeding to the next stage.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = DomainCompletionChecker(
        ...     name="domaincompletionchecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker ensures that the minimum required completions for a workflow stage are met before allowing progression.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        evaluate_progress_count = 0
        verify_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == MetacognitiveCore.EVALUATE_PROGRESS:
                    evaluate_progress_count += 1
                    last_output_state = item.output_state
                if item.instruction == NormativeCore.VERIFY:
                    verify_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Completion/Requirement Check: Ensure minimum required executions
        total_count = sum([evaluate_progress_count, verify_count])
        min_required = getattr(self, 'min_required', 1)
        
        if total_count < min_required:
            # Remove f-string variables from error message template as they may not exist in context
            base_error_msg = """Execution blocked: Workflow stage not completed. Required completions: {min_required}, Actual: {actual_completions}.""".split('{')[0].rstrip('.')
            error_msg = (
                f"{base_error_msg}."
                f" Required: {min_required}, Found: {total_count}"
            )
            logger.warning(f"[{self.name}] {error_msg}")
            
            if self.strict_mode:
                raise PolicyViolationError(
                    self.name, 
                    error_msg,
                    {"required": min_required, "found": total_count}
                )
            return False

        # Log successful validation
        logger.info(
            f"[{self.name}] DomainCompletionChecker validation PASSED: "
            f"EVALUATE_PROGRESS={evaluate_progress_count}, "
            f"VERIFY={verify_count}"
        )

        return True


@dataclass
class ComplianceChecker(PolicyChecker):
    """Validates that all operations comply with regulatory requirements, particularly focusing on risk thresholds and approval flags.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = ComplianceChecker(
        ...     name="compliancechecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker blocks operations if the risk level exceeds max_risk_threshold or if an operation requires approval and it hasn't been granted.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        tool_call_count = 0
        constrain_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == ExecutionCore.TOOL_CALL:
                    tool_call_count += 1
                    last_output_state = item.output_state
                if item.instruction == NormativeCore.CONSTRAIN:
                    constrain_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Compliance Check: Validate state meets requirements before critical actions
        if last_output_state:
            # Check for required approval or validation flags
            is_validated = last_output_state.get('validated', False)
            is_approved = last_output_state.get('approved', False)
            risk_level = last_output_state.get('risk_level', 0.0)
            
            # Block high-risk operations without validation
            max_risk_threshold = getattr(self, 'max_risk_threshold', 0.8)
            requires_approval = getattr(self, 'requires_approval', False)
            
            if isinstance(risk_level, (int, float)) and risk_level > max_risk_threshold:
                error_msg = (
                    f"Execution blocked: Compliance check failed. Risk level: {risk_level}, Approval required: {requires_approval}."
                    f" Risk level {risk_level} exceeds threshold {max_risk_threshold}"
                )
                logger.warning(f"[{self.name}] {error_msg}")
                
                if self.strict_mode:
                    raise PolicyViolationError(
                        self.name,
                        error_msg,
                        {"risk_level": risk_level, "threshold": max_risk_threshold}
                    )
                return False
            
            if requires_approval and not is_approved:
                error_msg = f"Execution blocked: Compliance check failed. Risk level: {risk_level}, Approval required: {requires_approval}. Operation requires approval."
                logger.warning(f"[{self.name}] {error_msg}")
                
                if self.strict_mode:
                    raise PolicyViolationError(self.name, error_msg, {"approved": is_approved})
                return False

        # Log successful validation
        logger.info(
            f"[{self.name}] ComplianceChecker validation PASSED: "
            f"TOOL_CALL={tool_call_count}, "
            f"CONSTRAIN={constrain_count}"
        )

        return True


# =============================================================================
# Verification Node Utilities
# =============================================================================

def create_verification_checker(
    name: str,
    target_instruction: "InstructionType",
    verification_instruction: "InstructionType",
    min_verifications: int = 1,
    strict_mode: bool = True,
) -> PolicyChecker:
    """Factory function to create a verification requirement checker.
    
    This creates a checker that ensures a verification step has been executed
    before allowing the target instruction to proceed.
    
    Args:
        name: Name for the checker.
        target_instruction: The instruction type that requires verification.
        verification_instruction: The instruction type that provides verification.
        min_verifications: Minimum number of verification steps required.
        strict_mode: If True, raises error on failure.
        
    Returns:
        A configured PolicyChecker instance.
        
    Example:
        >>> # Require VERIFY before TOOL_CALL (trading execution)
        >>> checker = create_verification_checker(
        ...     name="require_verify_before_trade",
        ...     target_instruction=ExecutionCore.TOOL_CALL,
        ...     verification_instruction=NormativeCore.VERIFY,
        ...     min_verifications=1
        ... )
    """
    from arbiteros_alpha.instructions import NormativeCore
    
    @dataclass
    class DynamicVerificationChecker(PolicyChecker):
        name: str
        target_instruction: "InstructionType"
        verification_instruction: "InstructionType"
        min_verifications: int = 1
        strict_mode: bool = True
        
        def check_before(self, history: History) -> bool:
            if not history.entries:
                return True
                
            verification_count = 0
            target_pending = False
            
            for superstep in history.entries:
                for item in superstep:
                    if item.instruction == self.verification_instruction:
                        verification_count += 1
                    if item.instruction == self.target_instruction:
                        # Check if verification happened before this target
                        if verification_count < self.min_verifications:
                            error_msg = (
                                f"Instruction {self.target_instruction.name} requires "
                                f"at least {self.min_verifications} {self.verification_instruction.name} "
                                f"step(s). Found: {verification_count}"
                            )
                            logger.warning(f"[{self.name}] {error_msg}")
                            
                            if self.strict_mode:
                                raise PolicyViolationError(self.name, error_msg)
                            return False
            
            return True
    
    return DynamicVerificationChecker(
        name=name,
        target_instruction=target_instruction,
        verification_instruction=verification_instruction,
        min_verifications=min_verifications,
        strict_mode=strict_mode
    )