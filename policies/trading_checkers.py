"""trading-specific policy checkers for ArbiterOS governance.

This module provides policy checkers designed for the trading
multi-agent framework, enforcing workflow constraints and safety requirements.

PolicyCheckers validate execution constraints BEFORE instruction execution.
If validation fails, the checker returns False and blocks the execution,
preventing unsafe or invalid operations from proceeding.

Generated by ArbiterOS Migration Tool.
"""

import logging
from dataclasses import dataclass, field
from typing import List, Set, Optional

from arbiteros_alpha.history import History
from arbiteros_alpha.instructions import (
    CognitiveCore,
    ExecutionCore,
    NormativeCore,
    SocialCore,
)
from arbiteros_alpha.policy import PolicyChecker

logger = logging.getLogger(__name__)


class PolicyViolationError(Exception):
    """Raised when a policy check fails and blocks execution."""
    
    def __init__(self, policy_name: str, message: str, history_context: dict = None):
        self.policy_name = policy_name
        self.message = message
        self.history_context = history_context or {}
        super().__init__(f"[{policy_name}] {message}")


@dataclass
class VerificationRequirementChecker(PolicyChecker):
    """Ensures that a VERIFY instruction has been executed before any high-risk actions, such as TOOL_CALL, are performed.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = VerificationRequirementChecker(
        ...     name="verificationrequirementchecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker counts the number of VERIFY instructions in the history. If the count is less than the specified min_verifications, it blocks the execution of high-risk instructions.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        verify_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == NormativeCore.VERIFY:
                    verify_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Completion/Requirement Check: Ensure minimum required executions
        total_count = sum([verify_count])
        min_required = getattr(self, 'min_required', 1)
        
        if total_count < min_required:
            # Remove f-string variables from error message template as they may not exist in context
            base_error_msg = """Execution blocked: High-risk operation requires at least {min_verifications} verification(s).""".split('{')[0].rstrip('.')
            error_msg = (
                f"{base_error_msg}."
                f" Required: {min_required}, Found: {total_count}"
            )
            logger.warning(f"[{self.name}] {error_msg}")
            
            if self.strict_mode:
                raise PolicyViolationError(
                    self.name, 
                    error_msg,
                    {"required": min_required, "found": total_count}
                )
            return False

        # Log successful validation
        logger.info(
            f"[{self.name}] VerificationRequirementChecker validation PASSED: "
            f"VERIFY={verify_count}"
        )

        return True


@dataclass
class DataAvailabilityChecker(PolicyChecker):
    """Ensures that all required data fields are present before processing an instruction.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = DataAvailabilityChecker(
        ...     name="dataavailabilitychecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker verifies that all specified required_fields are present and not None in the input state before allowing the instruction to proceed.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        generate_count = 0
        tool_call_count = 0
        delegate_count = 0
        verify_count = 0
        negotiate_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == CognitiveCore.GENERATE:
                    generate_count += 1
                    last_output_state = item.output_state
                if item.instruction == ExecutionCore.TOOL_CALL:
                    tool_call_count += 1
                    last_output_state = item.output_state
                if item.instruction == ExecutionCore.DELEGATE:
                    delegate_count += 1
                    last_output_state = item.output_state
                if item.instruction == NormativeCore.VERIFY:
                    verify_count += 1
                    last_output_state = item.output_state
                if item.instruction == SocialCore.NEGOTIATE:
                    negotiate_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Data Availability Check: Ensure required data is present
        if last_output_state:
            required_fields = getattr(self, 'required_fields', [])
            missing_fields = [f for f in required_fields if f not in last_output_state or last_output_state[f] is None]
            
            if missing_fields:
                error_msg = (
                    f"Execution blocked: Missing required data fields: {missing_fields}."
                    f" Missing required data fields: {missing_fields}"
                )
                logger.warning(f"[{self.name}] {error_msg}")
                
                if self.strict_mode:
                    raise PolicyViolationError(
                        self.name,
                        error_msg,
                        {"missing_fields": missing_fields}
                    )
                return False

        # Log successful validation
        logger.info(
            f"[{self.name}] DataAvailabilityChecker validation PASSED: "
            f"GENERATE={generate_count}, "
            f"TOOL_CALL={tool_call_count}, "
            f"DELEGATE={delegate_count}, "
            f"VERIFY={verify_count}, "
            f"NEGOTIATE={negotiate_count}"
        )

        return True


@dataclass
class RiskThresholdChecker(PolicyChecker):
    """Blocks operations that exceed a specified risk threshold, ensuring that high-risk actions are not executed without proper approval.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = RiskThresholdChecker(
        ...     name="riskthresholdchecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker examines the risk_level in the output state. If the risk_level exceeds max_risk_threshold, it blocks the operation unless an 'approved' flag is present.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        tool_call_count = 0
        verify_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == ExecutionCore.TOOL_CALL:
                    tool_call_count += 1
                    last_output_state = item.output_state
                if item.instruction == NormativeCore.VERIFY:
                    verify_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Generic validation: Log and pass (customize for specific domains)
        # This is a fallback - domain-specific logic should be added above

        # Log successful validation
        logger.info(
            f"[{self.name}] RiskThresholdChecker validation PASSED: "
            f"TOOL_CALL={tool_call_count}, "
            f"VERIFY={verify_count}"
        )

        return True


@dataclass
class ComplianceChecker(PolicyChecker):
    """Validates that operations comply with regulatory requirements, blocking those that do not meet compliance standards.

    This checker enforces safety constraints by validating execution state
    BEFORE allowing the instruction to proceed. If validation fails, the
    instruction is BLOCKED.

    Attributes:
        name: Human-readable name for this policy checker.
        strict_mode: If True, raises PolicyViolationError on failure. If False, logs warning and returns False.

    Example:
        >>> checker = ComplianceChecker(
        ...     name="compliancechecker",
        ...     strict_mode=True,
        ... )
        >>> arbiter_os.add_policy_checker(checker)
    """

    name: str
    strict_mode: bool = True  # Default to strict enforcement

    def check_before(self, history: History) -> bool:
        """This checker ensures that operations do not exceed a specified risk threshold and checks for an 'approved' flag for high-risk operations.

        This method ENFORCES the policy constraint. If the constraint is violated:
        - In strict_mode: raises PolicyViolationError to halt execution
        - Otherwise: returns False to block the instruction

        Args:
            history: The execution history up to this point.

        Returns:
            True if validation passes and execution may proceed.
            False if validation fails and execution should be blocked.

        Raises:
            PolicyViolationError: In strict_mode when validation fails.
        """
        if not history.entries:
            logger.debug(f"[{self.name}] No history entries, allowing execution")
            return True

        # Count relevant instructions across all supersteps
        tool_call_count = 0
        verify_count = 0
        
        # Track the last outputs for state validation
        last_output_state = None
        
        for superstep in history.entries:
            for item in superstep:
                if item.instruction == ExecutionCore.TOOL_CALL:
                    tool_call_count += 1
                    last_output_state = item.output_state
                if item.instruction == NormativeCore.VERIFY:
                    verify_count += 1
                    last_output_state = item.output_state

        # === VALIDATION LOGIC ===
        # Implement domain-specific validation based on instruction counts and state
        
        # Compliance Check: Validate state meets requirements before critical actions
        if last_output_state:
            # Check for required approval or validation flags
            is_validated = last_output_state.get('validated', False)
            is_approved = last_output_state.get('approved', False)
            risk_level = last_output_state.get('risk_level', 0.0)
            
            # Block high-risk operations without validation
            max_risk_threshold = getattr(self, 'max_risk_threshold', 0.8)
            requires_approval = getattr(self, 'requires_approval', False)
            
            if isinstance(risk_level, (int, float)) and risk_level > max_risk_threshold:
                error_msg = (
                    f"Execution blocked: Operation does not meet compliance standards. Risk level: {risk_level}, Approval required: {requires_approval}."
                    f" Risk level {risk_level} exceeds threshold {max_risk_threshold}"
                )
                logger.warning(f"[{self.name}] {error_msg}")
                
                if self.strict_mode:
                    raise PolicyViolationError(
                        self.name,
                        error_msg,
                        {"risk_level": risk_level, "threshold": max_risk_threshold}
                    )
                return False
            
            if requires_approval and not is_approved:
                error_msg = f"Execution blocked: Operation does not meet compliance standards. Risk level: {risk_level}, Approval required: {requires_approval}. Operation requires approval."
                logger.warning(f"[{self.name}] {error_msg}")
                
                if self.strict_mode:
                    raise PolicyViolationError(self.name, error_msg, {"approved": is_approved})
                return False

        # Log successful validation
        logger.info(
            f"[{self.name}] ComplianceChecker validation PASSED: "
            f"TOOL_CALL={tool_call_count}, "
            f"VERIFY={verify_count}"
        )

        return True


# =============================================================================
# Verification Node Utilities
# =============================================================================

def create_verification_checker(
    name: str,
    target_instruction: "InstructionType",
    verification_instruction: "InstructionType",
    min_verifications: int = 1,
    strict_mode: bool = True,
) -> PolicyChecker:
    """Factory function to create a verification requirement checker.
    
    This creates a checker that ensures a verification step has been executed
    before allowing the target instruction to proceed.
    
    Args:
        name: Name for the checker.
        target_instruction: The instruction type that requires verification.
        verification_instruction: The instruction type that provides verification.
        min_verifications: Minimum number of verification steps required.
        strict_mode: If True, raises error on failure.
        
    Returns:
        A configured PolicyChecker instance.
        
    Example:
        >>> # Require VERIFY before TOOL_CALL (trading execution)
        >>> checker = create_verification_checker(
        ...     name="require_verify_before_trade",
        ...     target_instruction=ExecutionCore.TOOL_CALL,
        ...     verification_instruction=NormativeCore.VERIFY,
        ...     min_verifications=1
        ... )
    """
    from arbiteros_alpha.instructions import NormativeCore
    
    @dataclass
    class DynamicVerificationChecker(PolicyChecker):
        name: str
        target_instruction: "InstructionType"
        verification_instruction: "InstructionType"
        min_verifications: int = 1
        strict_mode: bool = True
        
        def check_before(self, history: History) -> bool:
            if not history.entries:
                return True
                
            verification_count = 0
            target_pending = False
            
            for superstep in history.entries:
                for item in superstep:
                    if item.instruction == self.verification_instruction:
                        verification_count += 1
                    if item.instruction == self.target_instruction:
                        # Check if verification happened before this target
                        if verification_count < self.min_verifications:
                            error_msg = (
                                f"Instruction {self.target_instruction.name} requires "
                                f"at least {self.min_verifications} {self.verification_instruction.name} "
                                f"step(s). Found: {verification_count}"
                            )
                            logger.warning(f"[{self.name}] {error_msg}")
                            
                            if self.strict_mode:
                                raise PolicyViolationError(self.name, error_msg)
                            return False
            
            return True
    
    return DynamicVerificationChecker(
        name=name,
        target_instruction=target_instruction,
        verification_instruction=verification_instruction,
        min_verifications=min_verifications,
        strict_mode=strict_mode
    )